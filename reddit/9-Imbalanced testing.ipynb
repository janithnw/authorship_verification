{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, average_precision_score\n",
    "import random\n",
    "from train_utils import generate_doc_pairs_no_chunking\n",
    "from utills import chunker, cartesian_product, ReservoirSample\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BASE_PATH = '../data/reddit_2/'\n",
    "COMPUTED_DATA_PATH = '../temp_data/reddit_old_dec/preprocessed/'\n",
    "chunk_sz=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "with open('../temp_data/reddit_old_dec/unchunked/model.p', 'rb') as f:\n",
    "    (clf_nc, transformer_nc, scaler_nc, secondary_scaler_nc, _) = pickle.load(f)\n",
    "    \n",
    "with open('../temp_data/reddit_old_dec/multidoc_20/model_20.p', 'rb') as f:\n",
    "    (clf, transformer, scaler, secondary_scaler, _) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../temp_data/reddit_old_dec/unchunked/experiment_data.p', 'rb') as f:\n",
    "    (_, author_to_doc_idx_nc,  _, author_subreddit_nc, _, x_shape_nc, _, _, _, _) = pickle.load(f)\n",
    "with open('../temp_data/reddit_old_dec/multidoc_20/experiment_data20.p', 'rb') as f:\n",
    "    (_, author_bounds_c, _, author_subreddit_c, _, x_shape_c, _, _, _, _) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX_nc = np.memmap('../temp_data/reddit_old_dec/unchunked/XX_test.npy', dtype='float32', mode='r', shape=x_shape_nc)\n",
    "XX_c = np.memmap('../temp_data/reddit_old_dec/multidoc_20/XX_test_20.npy', dtype='float32', mode='r', shape=x_shape_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Test Pairs\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_idx_to_author = {v:k for k, v in author_to_doc_idx_nc.items()}\n",
    "author_mapping = defaultdict(set)\n",
    "author_to_root = {}\n",
    "for y in author_to_doc_idx_nc.keys():\n",
    "    u = re.search(r'(.*)_[A-Z]+$', y).group(1)\n",
    "    author_mapping[u].add(y)\n",
    "    author_to_root[y] = u\n",
    "\n",
    "subreddit_to_author = defaultdict(list)\n",
    "for k, v in author_subreddit_nc.items():\n",
    "    subreddit_to_author[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e897d20bee1d4b30bcf802ee47c96bfb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd19e519652469c98b2409725695dbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da7f4796de74bfe87b8638f41a1e9bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "45652 42961 36920\n"
     ]
    }
   ],
   "source": [
    "X_idxs_pos, X_idxs_neg_diff_topic, X_idxs_neg_same_topic = generate_doc_pairs_no_chunking(author_mapping, subreddit_to_author, author_to_root, author_to_doc_idx_nc, author_subreddit_c, return_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X_idxs):\n",
    "    probs_nc = []\n",
    "\n",
    "\n",
    "    inter_probs_mean = []\n",
    "    inter_probs_std = []\n",
    "\n",
    "    intraA_probs_mean = []\n",
    "    intraA_probs_std = []\n",
    "\n",
    "    intraB_probs_mean = []\n",
    "    intraB_probs_std = []\n",
    "    pred_lengths = []\n",
    "\n",
    "\n",
    "    for i, j in tqdm(X_idxs):\n",
    "        user_a = doc_idx_to_author[i]\n",
    "        user_b = doc_idx_to_author[j]\n",
    "\n",
    "        start_a, end_a = author_bounds_c[user_a]\n",
    "        start_b, end_b = author_bounds_c[user_b]\n",
    "\n",
    "        l = []\n",
    "        idxs = cartesian_product(range(start_a, end_a), range(start_b, end_b))\n",
    "        x_diff = secondary_scaler.transform(np.abs(XX_c[idxs[:, 0]] - XX_c[idxs[:, 1]]))\n",
    "        x_diff[np.isnan(x_diff)]=0\n",
    "        p = clf.predict_proba(x_diff)[:, 1]\n",
    "        inter_probs_mean.append(p.mean())\n",
    "        inter_probs_std.append(p.std())\n",
    "        l.append(len(p))\n",
    "\n",
    "        idxs = cartesian_product(range(start_a, end_a), range(start_a, end_a))\n",
    "        idxs = np.array([(i, j) for i, j in idxs if i != j])\n",
    "        x_diff = secondary_scaler.transform(np.abs(XX_c[idxs[:, 0]] - XX_c[idxs[:, 1]]))\n",
    "        x_diff[np.isnan(x_diff)]=0\n",
    "        p = clf.predict_proba(x_diff)[:, 1]\n",
    "        intraA_probs_mean.append(p.mean())\n",
    "        intraA_probs_std.append(p.std())\n",
    "        l.append(len(p))\n",
    "\n",
    "        idxs = cartesian_product(range(start_b, end_b), range(start_b, end_b))\n",
    "        idxs = np.array([(i, j) for i, j in idxs if i != j])\n",
    "        x_diff = secondary_scaler.transform(np.abs(XX_c[idxs[:, 0]] - XX_c[idxs[:, 1]]))\n",
    "        x_diff[np.isnan(x_diff)]=0\n",
    "        p = clf.predict_proba(x_diff)[:, 1]\n",
    "        intraB_probs_mean.append(p.mean())\n",
    "        intraB_probs_std.append(p.std())\n",
    "        l.append(len(p))\n",
    "\n",
    "        pred_lengths.append(l)\n",
    "\n",
    "        p = clf_nc.predict_proba(secondary_scaler_nc.transform(np.abs(XX_nc[[i], :] - XX_nc[[j], :])))[0, 1]\n",
    "        probs_nc.append(p)\n",
    "        \n",
    "\n",
    "    inter_probs_mean = np.array(inter_probs_mean)\n",
    "    intraA_probs_mean = np.array(intraA_probs_mean)\n",
    "    intraB_probs_mean = np.array(intraB_probs_mean)\n",
    "    inter_probs_std = np.array(inter_probs_std)\n",
    "    intraA_probs_std = np.array(intraA_probs_std)\n",
    "    intraB_probs_std = np.array(intraB_probs_std)\n",
    "    pred_lengths = np.array(pred_lengths)\n",
    "\n",
    "\n",
    "    probs_nc = np.array(probs_nc)\n",
    "\n",
    "    n_a = pred_lengths[:, 0]\n",
    "    n_b = pred_lengths[:, 1]\n",
    "    n_ab = pred_lengths[:, 2]\n",
    "\n",
    "    intra_probs_mean = (intraA_probs_mean * n_a + intraB_probs_mean * n_b)/ (n_a + n_b)\n",
    "    intra_probs_std = (\n",
    "            n_a * (intraA_probs_std ** 2 + (intraA_probs_mean - intra_probs_mean)**2) + \n",
    "            n_b * (intraB_probs_std ** 2 + (intraB_probs_mean - intra_probs_mean)**2)\n",
    "        ) / (n_a + n_b)\n",
    "\n",
    "\n",
    "    pooled_mean = (intra_probs_mean * (n_a + n_b) + inter_probs_mean * n_ab)/ (n_a + n_b + n_ab)\n",
    "    pooled_std = (\n",
    "            (n_a + n_b) * (intra_probs_mean ** 2 + (intra_probs_mean - pooled_mean)**2) + \n",
    "            n_ab * (inter_probs_mean ** 2 + (inter_probs_mean - pooled_mean)**2)\n",
    "        ) / (n_a + n_b + n_ab)\n",
    "\n",
    "    aggr_score = (probs_nc * (1 - np.abs(inter_probs_mean - intra_probs_mean)))\n",
    "    return aggr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77a80dc4922445087ca48cdcf2bbcae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620351e1f97645959aa22013a75548b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2b1332d6ac4fbd826fe4475c2ec19e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_preds = predict(X_idxs_pos)\n",
    "neg_diff_topic_preds = predict(X_idxs_neg_diff_topic)\n",
    "neg_same_topic_preds = predict(X_idxs_neg_same_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../temp_data/reddit_old_dec/class_imbalance/experiment_data.p', 'wb') as f:\n",
    "    pickle.dump((\n",
    "        X_idxs_pos,\n",
    "        X_idxs_neg_diff_topic,\n",
    "        X_idxs_neg_same_topic,\n",
    "        pos_preds,\n",
    "        neg_diff_topic_preds,\n",
    "        neg_same_topic_preds\n",
    "    ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = np.random.choice(np.arange(len(X_idxs_neg_diff_topic)), size=len(X_idxs_neg_diff_topic), replace=False)\n",
    "neg_diff_topic_preds_sampled = neg_diff_topic_preds[p]\n",
    "\n",
    "p = np.random.choice(np.arange(len(X_idxs_neg_same_topic)), size=len(X_idxs_neg_same_topic), replace=False)\n",
    "neg_same_topic_preds_sampled = neg_same_topic_preds[p]\n",
    "\n",
    "neg_preds = np.concatenate([neg_diff_topic_preds_sampled, neg_same_topic_preds_sampled])\n",
    "\n",
    "# preds = np.concatenate([pos_preds, neg_diff_topic_preds_sampled, neg_same_topic_preds_sampled])\n",
    "# labels = np.array([1] * len(pos_preds) + [0] * len(neg_diff_topic_preds_sampled) + [0] * len(neg_same_topic_preds_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42961, 36920, 79881)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_idxs_neg_diff_topic), len(X_idxs_neg_same_topic), len(neg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.984   &   0.982   &   0.973   &   0.947   &   0.933   &  \n",
      "0.25 0.984   &   0.954   &   0.89   &   0.857   &   0.932   &  \n",
      "0.1 0.984   &   0.89   &   0.675   &   0.667   &   0.933   &  \n",
      "0.05 0.984   &   0.815   &   0.412   &   0.487   &   0.932   &  \n",
      "0.01 0.984   &   0.541   &   0.011   &   0.155   &   0.934   &  \n",
      "0.005 0.984   &   0.409   &   0.001   &   0.083   &   0.935   &  \n"
     ]
    }
   ],
   "source": [
    "total_recs = 79000\n",
    "pos_fracs = [0.5, 0.25, 0.1, 0.05, 0.01, 0.005]\n",
    "# fig = plt.figure()\n",
    "\n",
    "for frac in pos_fracs:\n",
    "    roc_aucs = []\n",
    "    pr_aucs = []\n",
    "    r_at_ps = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    for _ in range(10):\n",
    "        pos_preds_sampled = np.random.choice(pos_preds, int(total_recs * frac), replace=False)\n",
    "        neg_preds_sampled = np.random.choice(neg_preds, int(total_recs * (1-frac)), replace=False)\n",
    "\n",
    "        preds = np.concatenate([pos_preds_sampled, neg_preds_sampled])\n",
    "        labels = np.array([1] * len(pos_preds_sampled) + [0] * len(neg_preds_sampled))\n",
    "#         print(len(labels), labels.sum())\n",
    "        precision, recall, thresh = precision_recall_curve(labels, preds)\n",
    "    #         plt.plot(precision, recall, label=str(frac))\n",
    "        _, r_at_p = recall_at_precision(precision, recall, precision_value=0.90)\n",
    "        # plt.plot([p_at_r_x], [p_at_r_y], marker='o')\n",
    "        pr_auc = average_precision_score(labels, preds)\n",
    "\n",
    "        fpr, tpr, thresh = roc_curve(labels, preds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        precision = precision_score(labels, preds > 0.5)\n",
    "        recall = recall_score(labels, preds > 0.5)\n",
    "\n",
    "        roc_aucs.append(roc_auc)\n",
    "        pr_aucs.append(pr_auc)\n",
    "        r_at_ps.append(r_at_p)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        \n",
    "#     print(frac, \n",
    "#           'AUC:', round(np.mean(roc_aucs), 4), \n",
    "#           'PR_AUC:', round(np.mean(pr_aucs), 4), \n",
    "#           'R@P90:', np.mean(r_at_ps),\n",
    "#           'P:', np.mean(precision_scores), \n",
    "#           'R:', np.mean(recall_scores)\n",
    "#          )\n",
    "    print(frac, \n",
    "          round(np.mean(roc_aucs), 3), '  &  ',\n",
    "          round(np.mean(pr_aucs), 3), '  &  ',\n",
    "          round(np.mean(r_at_ps), 3),'  &  ',\n",
    "          round(np.mean(precision_scores), 3), '  &  ',\n",
    "          round(np.mean(recall_scores), 3), '  &  '\n",
    "         )\n",
    "# fig.legend(loc='lower left', bbox_to_anchor=(0.1, 0.15))\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision, recall, thresh = precision_recall_curve(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_at_precision(precisions, recalls, precision_value=0.9):\n",
    "    res = np.argwhere(precisions > precision_value)\n",
    "    idx = 0\n",
    "    if len(res) > 0:\n",
    "        idx = res[0][0]\n",
    "    return precisions[idx], recalls[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain Classifier with Different Class Weights\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../temp_data/reddit_old_dec/unchunked/experiment_data.p', 'rb') as f:\n",
    "    (\n",
    "        author_to_doc_idx, \n",
    "        author_to_doc_idx_test, \n",
    "        author_subreddit, \n",
    "        author_subreddit_test, \n",
    "        x_shape, \n",
    "        x_shape_test,\n",
    "        X_idxs_train,\n",
    "        Y_train,\n",
    "        X_idxs_test,\n",
    "        Y_test\n",
    "    ) = pickle.load(f)\n",
    "    \n",
    "XX_train = np.memmap('../temp_data/reddit_old_dec/unchunked/XX_train.npy', dtype='float32', mode='r', shape=x_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_recs = 10000\n",
    "frac = 0.01\n",
    "X_idxs_neg = np.concatenate([X_idxs_neg_diff_topic, X_idxs_neg_same_topic])\n",
    "p = np.random.choice(range(len(X_idxs_neg)), int(total_recs * (1 - frac)), replace=False)\n",
    "X_idxs_neg_sampled = X_idxs_neg[p]\n",
    "p = np.random.choice(range(len(X_idxs_pos)), int(total_recs * frac), replace=False)\n",
    "X_idxs_pos_sampled = X_idxs_pos[p]\n",
    "\n",
    "X_idxs_test_sample = np.concatenate([X_idxs_pos_sampled, X_idxs_neg_sampled])\n",
    "y_test_sample = np.array([1] * len(X_idxs_pos_sampled) + [0] * len(X_idxs_neg_sampled))\n",
    "\n",
    "x_test_diff_sample = secondary_scaler_nc.transform(np.abs(XX_nc[X_idxs_test_sample[:, 0]] - XX_nc[X_idxs_test_sample[:, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHT: {0: 0.1, 1: 0.9}\n",
      "AUC: 0.8862848484848485 PR_AUC: 0.045808835047057454\n",
      "AUC: 0.9205318181818181 PR_AUC: 0.06615292727442247\n",
      "AUC: 0.9243131313131312 PR_AUC: 0.09388921595046973\n",
      "AUC: 0.9442601010101009 PR_AUC: 0.11368438350198225\n",
      "AUC: 0.9385722222222223 PR_AUC: 0.10229066896897222\n",
      "AUC: 0.9469358585858586 PR_AUC: 0.11150689720197171\n",
      "AUC: 0.9429055555555556 PR_AUC: 0.13671573280731833\n",
      "AUC: 0.9413338383838384 PR_AUC: 0.13748901929694618\n",
      "AUC: 0.9497085858585859 PR_AUC: 0.12749633665593127\n",
      "AUC: 0.9522565656565657 PR_AUC: 0.14072232510675206\n",
      "AUC: 0.9519424242424241 PR_AUC: 0.1405421670456858\n",
      "AUC: 0.9496277777777778 PR_AUC: 0.13565259579355407\n",
      "AUC: 0.9538808080808081 PR_AUC: 0.15265196323097635\n",
      "AUC: 0.952189898989899 PR_AUC: 0.14524652949725586\n",
      "AUC: 0.9509636363636363 PR_AUC: 0.1710925049594791\n",
      "AUC: 0.9529515151515152 PR_AUC: 0.1601118456095976\n",
      "AUC: 0.9480328282828283 PR_AUC: 0.16065370148195854\n",
      "AUC: 0.9499065656565657 PR_AUC: 0.15559226417849717\n",
      "AUC: 0.9489449494949495 PR_AUC: 0.1498420591584527\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  0\n",
      "AUC: 0.9529510101010101 PR_AUC: 0.15636429558453196\n",
      "AUC: 0.9531702020202021 PR_AUC: 0.15010433965636422\n",
      "AUC: 0.9505469696969697 PR_AUC: 0.14638326087163342\n",
      "AUC: 0.9513984848484848 PR_AUC: 0.1621244565135833\n",
      "AUC: 0.9523419191919192 PR_AUC: 0.1603024412720248\n",
      "AUC: 0.951580808080808 PR_AUC: 0.1595995862683233\n",
      "AUC: 0.9518489898989898 PR_AUC: 0.16612097569465784\n",
      "AUC: 0.9520065656565656 PR_AUC: 0.16297203796905882\n",
      "AUC: 0.9490131313131314 PR_AUC: 0.1529022240115348\n",
      "AUC: 0.9487282828282829 PR_AUC: 0.15286230198254933\n",
      "AUC: 0.9515999999999999 PR_AUC: 0.1686256889973705\n",
      "AUC: 0.9487050505050506 PR_AUC: 0.15359298490835904\n",
      "AUC: 0.9481767676767676 PR_AUC: 0.16182296138539118\n",
      "AUC: 0.949319191919192 PR_AUC: 0.15730307592689363\n",
      "AUC: 0.9455050505050505 PR_AUC: 0.15529383857646764\n",
      "AUC: 0.9474732323232322 PR_AUC: 0.15860999682679153\n",
      "AUC: 0.9460378787878787 PR_AUC: 0.1655043493749038\n",
      "AUC: 0.9452954545454545 PR_AUC: 0.1677811881617091\n",
      "AUC: 0.9463737373737374 PR_AUC: 0.16215697908152124\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  1\n",
      "AUC: 0.9466494949494949 PR_AUC: 0.1605402624961667\n",
      "AUC: 0.9483080808080807 PR_AUC: 0.15313414600959324\n",
      "AUC: 0.9454181818181818 PR_AUC: 0.17138425046113898\n",
      "AUC: 0.9455747474747475 PR_AUC: 0.17557547457873512\n",
      "AUC: 0.9436929292929293 PR_AUC: 0.1679667223355749\n",
      "AUC: 0.9457459595959595 PR_AUC: 0.1632030063792665\n",
      "AUC: 0.9444969696969696 PR_AUC: 0.175438703944052\n",
      "AUC: 0.9454868686868687 PR_AUC: 0.16432317653640305\n",
      "AUC: 0.9512368686868687 PR_AUC: 0.1676784109312235\n",
      "AUC: 0.9503388888888888 PR_AUC: 0.1653958954388807\n",
      "AUC: 0.9516434343434345 PR_AUC: 0.17884144794153606\n",
      "AUC: 0.9506282828282828 PR_AUC: 0.16613213364036802\n",
      "AUC: 0.9494696969696969 PR_AUC: 0.16335199168929299\n",
      "AUC: 0.9501474747474747 PR_AUC: 0.16193716470410266\n",
      "AUC: 0.9495545454545454 PR_AUC: 0.17281696715454611\n",
      "AUC: 0.9494868686868686 PR_AUC: 0.17255830716482434\n",
      "AUC: 0.9480545454545455 PR_AUC: 0.16967728475305288\n",
      "AUC: 0.9479126262626263 PR_AUC: 0.17354913949594958\n",
      "AUC: 0.9487641414141414 PR_AUC: 0.16788474383884283\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  2\n",
      "AUC: 0.9522929292929292 PR_AUC: 0.17869350697233824\n",
      "AUC: 0.951809595959596 PR_AUC: 0.17151716548209664\n",
      "AUC: 0.949428282828283 PR_AUC: 0.16726892647836658\n",
      "AUC: 0.9496833333333333 PR_AUC: 0.1703588521710315\n",
      "AUC: 0.9477080808080808 PR_AUC: 0.1692755639910084\n",
      "AUC: 0.9484601010101011 PR_AUC: 0.16620435420777424\n",
      "AUC: 0.9478828282828283 PR_AUC: 0.1737413331196942\n",
      "AUC: 0.9479974747474746 PR_AUC: 0.16002716827541613\n",
      "AUC: 0.9483853535353536 PR_AUC: 0.16543441658533567\n",
      "AUC: 0.9476020202020202 PR_AUC: 0.16217274471390378\n",
      "AUC: 0.9484919191919191 PR_AUC: 0.169451626782367\n",
      "AUC: 0.9481575757575756 PR_AUC: 0.15729624803341388\n",
      "AUC: 0.947640909090909 PR_AUC: 0.1608063961866742\n",
      "AUC: 0.9474914141414141 PR_AUC: 0.1582543389600999\n",
      "AUC: 0.9472116161616162 PR_AUC: 0.17264609384233123\n",
      "AUC: 0.9475636363636364 PR_AUC: 0.16516134970862378\n",
      "AUC: 0.9464803030303031 PR_AUC: 0.16340183704426292\n",
      "AUC: 0.9456429292929293 PR_AUC: 0.17326098193486933\n",
      "AUC: 0.9461585858585858 PR_AUC: 0.1701802768395434\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  3\n",
      "AUC: 0.948340909090909 PR_AUC: 0.17764576961956252\n",
      "AUC: 0.9488969696969697 PR_AUC: 0.16579144643628624\n",
      "AUC: 0.9474161616161616 PR_AUC: 0.17230880524423936\n",
      "AUC: 0.9478141414141414 PR_AUC: 0.1760024394565408\n",
      "AUC: 0.9454651515151515 PR_AUC: 0.17545226931565197\n",
      "AUC: 0.9455606060606061 PR_AUC: 0.1638431456272308\n",
      "AUC: 0.9449085858585858 PR_AUC: 0.1676156155482285\n",
      "AUC: 0.9456580808080807 PR_AUC: 0.1624407758505402\n",
      "AUC: 0.9487343434343435 PR_AUC: 0.15701771463479328\n",
      "AUC: 0.949049494949495 PR_AUC: 0.16275654938860729\n",
      "AUC: 0.9497242424242425 PR_AUC: 0.16947749385533745\n",
      "AUC: 0.9491570707070707 PR_AUC: 0.1566280781193195\n",
      "AUC: 0.9487212121212121 PR_AUC: 0.15874746362957176\n",
      "AUC: 0.947730303030303 PR_AUC: 0.15036597349903552\n",
      "AUC: 0.9475752525252525 PR_AUC: 0.16213818936665186\n",
      "AUC: 0.9474737373737374 PR_AUC: 0.1594536415882278\n",
      "AUC: 0.9468313131313131 PR_AUC: 0.16198552625189758\n",
      "AUC: 0.946510101010101 PR_AUC: 0.16474282107722518\n",
      "AUC: 0.9465742424242424 PR_AUC: 0.161327222300156\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  4\n",
      "AUC: 0.948319191919192 PR_AUC: 0.16435813860674478\n",
      "AUC: 0.9482616161616161 PR_AUC: 0.15938914156674017\n",
      "AUC: 0.9476358585858586 PR_AUC: 0.1652328042733523\n",
      "AUC: 0.9488732323232324 PR_AUC: 0.16715236412487197\n",
      "AUC: 0.9479949494949496 PR_AUC: 0.17066373817075736\n",
      "AUC: 0.9472964646464647 PR_AUC: 0.16211178824350242\n",
      "AUC: 0.9468055555555556 PR_AUC: 0.1718632919673328\n",
      "AUC: 0.9473686868686868 PR_AUC: 0.16193198633323921\n",
      "AUC: 0.9471171717171717 PR_AUC: 0.15535069345697972\n",
      "AUC: 0.9467111111111111 PR_AUC: 0.15586530923247657\n",
      "AUC: 0.9476550505050504 PR_AUC: 0.16524568520548444\n",
      "AUC: 0.9473227272727273 PR_AUC: 0.15511924872890723\n",
      "AUC: 0.9466040404040402 PR_AUC: 0.15496440442118864\n",
      "AUC: 0.9466020202020202 PR_AUC: 0.15293107457502148\n",
      "AUC: 0.9454565656565657 PR_AUC: 0.15456349564154906\n",
      "AUC: 0.9461717171717171 PR_AUC: 0.15945945529559843\n",
      "AUC: 0.9456717171717173 PR_AUC: 0.15862884391139448\n",
      "AUC: 0.9457055555555555 PR_AUC: 0.158380088965182\n",
      "AUC: 0.9455055555555555 PR_AUC: 0.1599137970531419\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  5\n",
      "AUC: 0.9471237373737372 PR_AUC: 0.16881924652730146\n",
      "AUC: 0.9478686868686869 PR_AUC: 0.16395176681652995\n",
      "AUC: 0.946970202020202 PR_AUC: 0.16652614480156688\n",
      "AUC: 0.9478474747474747 PR_AUC: 0.17051595888570398\n",
      "AUC: 0.9465823232323233 PR_AUC: 0.17290070049753517\n",
      "AUC: 0.9458797979797979 PR_AUC: 0.16610006972922478\n",
      "AUC: 0.9453818181818183 PR_AUC: 0.16569066343251773\n",
      "AUC: 0.9459545454545455 PR_AUC: 0.1602986788708532\n",
      "AUC: 0.9477252525252525 PR_AUC: 0.16090761608802065\n",
      "AUC: 0.9478984848484848 PR_AUC: 0.1645214681684459\n",
      "AUC: 0.9481136363636363 PR_AUC: 0.16714540742799508\n",
      "AUC: 0.9479479797979797 PR_AUC: 0.15961857406072116\n",
      "AUC: 0.9470489898989899 PR_AUC: 0.15466835698655712\n",
      "AUC: 0.9470292929292928 PR_AUC: 0.15322456678048274\n",
      "AUC: 0.9461479797979798 PR_AUC: 0.15697632290300326\n",
      "AUC: 0.9466944444444445 PR_AUC: 0.16019705372674353\n",
      "AUC: 0.9464363636363636 PR_AUC: 0.16185327709105038\n",
      "AUC: 0.9461242424242424 PR_AUC: 0.16464452690141648\n",
      "AUC: 0.9461954545454545 PR_AUC: 0.16295729264763872\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  6\n",
      "AUC: 0.9476949494949495 PR_AUC: 0.16702951788887394\n",
      "AUC: 0.9482095959595959 PR_AUC: 0.16509258415581796\n",
      "AUC: 0.9470909090909091 PR_AUC: 0.16402088647496066\n",
      "AUC: 0.9474080808080808 PR_AUC: 0.1651452910143554\n",
      "AUC: 0.9472055555555555 PR_AUC: 0.17365989439687923\n",
      "AUC: 0.9473267676767676 PR_AUC: 0.17631118598554535\n",
      "AUC: 0.946089393939394 PR_AUC: 0.16703301147015406\n",
      "AUC: 0.9466398989898989 PR_AUC: 0.16420009029394175\n",
      "AUC: 0.9473555555555555 PR_AUC: 0.15931726250389672\n",
      "AUC: 0.9469848484848485 PR_AUC: 0.15735158069623797\n",
      "AUC: 0.9472121212121212 PR_AUC: 0.15951130841490643\n",
      "AUC: 0.9471419191919191 PR_AUC: 0.15403060970501958\n",
      "AUC: 0.9468823232323231 PR_AUC: 0.15535370880860555\n",
      "AUC: 0.9475065656565655 PR_AUC: 0.16033663554977526\n",
      "AUC: 0.946710101010101 PR_AUC: 0.16205744339164502\n",
      "AUC: 0.946089393939394 PR_AUC: 0.1571875447248456\n",
      "AUC: 0.9458616161616162 PR_AUC: 0.1594298135597762\n",
      "AUC: 0.9457419191919192 PR_AUC: 0.16030612706283406\n",
      "AUC: 0.9457186868686869 PR_AUC: 0.1603846306979491\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  7\n",
      "AUC: 0.9467060606060606 PR_AUC: 0.16332299765720745\n",
      "AUC: 0.947238888888889 PR_AUC: 0.15914482494311757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9463797979797979 PR_AUC: 0.1574988095552654\n",
      "AUC: 0.9469853535353534 PR_AUC: 0.1605731078709888\n",
      "AUC: 0.9469161616161617 PR_AUC: 0.1721381791897677\n",
      "AUC: 0.9469489898989899 PR_AUC: 0.17369382319716484\n",
      "AUC: 0.9457141414141415 PR_AUC: 0.16476549172820268\n",
      "AUC: 0.9461575757575758 PR_AUC: 0.16234073231926643\n",
      "AUC: 0.9474292929292929 PR_AUC: 0.15894338269071653\n",
      "AUC: 0.9471848484848485 PR_AUC: 0.15782597461906625\n",
      "AUC: 0.9473939393939393 PR_AUC: 0.15856657194061544\n",
      "AUC: 0.9471959595959597 PR_AUC: 0.1537350182913365\n",
      "AUC: 0.9469580808080807 PR_AUC: 0.15539040094919082\n",
      "AUC: 0.9469500000000001 PR_AUC: 0.15290977611692189\n",
      "AUC: 0.946679797979798 PR_AUC: 0.16039227082592789\n",
      "AUC: 0.9473515151515152 PR_AUC: 0.16493226911226058\n",
      "AUC: 0.9469272727272727 PR_AUC: 0.16758919804051084\n",
      "AUC: 0.9466878787878789 PR_AUC: 0.16874889162528722\n",
      "AUC: 0.9459040404040403 PR_AUC: 0.1603416613630527\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  8\n",
      "AUC: 0.9477318181818181 PR_AUC: 0.1697468968477824\n",
      "AUC: 0.9480247474747474 PR_AUC: 0.16777189908370282\n",
      "AUC: 0.9467813131313132 PR_AUC: 0.16089335999915247\n",
      "AUC: 0.9471015151515151 PR_AUC: 0.16319984384493208\n",
      "AUC: 0.9465005050505051 PR_AUC: 0.16427155710200975\n",
      "AUC: 0.9466373737373738 PR_AUC: 0.16579541222286245\n",
      "AUC: 0.9462373737373738 PR_AUC: 0.16855836902491766\n",
      "AUC: 0.946709090909091 PR_AUC: 0.16390378111776585\n",
      "AUC: 0.947709090909091 PR_AUC: 0.166202210678906\n",
      "AUC: 0.9467474747474748 PR_AUC: 0.15876676386877522\n",
      "AUC: 0.9470358585858585 PR_AUC: 0.16035759541824285\n",
      "AUC: 0.9469914141414141 PR_AUC: 0.15579479694351586\n",
      "AUC: 0.9467742424242425 PR_AUC: 0.15619110562851185\n",
      "AUC: 0.9470323232323232 PR_AUC: 0.15780544160246435\n",
      "AUC: 0.9466752525252524 PR_AUC: 0.1628849346587296\n",
      "AUC: 0.9461959595959596 PR_AUC: 0.15749277251493998\n",
      "AUC: 0.9459636363636363 PR_AUC: 0.15932024024189242\n",
      "AUC: 0.946160606060606 PR_AUC: 0.16184230385140688\n",
      "AUC: 0.9461333333333334 PR_AUC: 0.16117112239580036\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  9\n",
      "AUC: 0.9477161616161617 PR_AUC: 0.1706304275336184\n",
      "AUC: 0.9479520202020202 PR_AUC: 0.16614687934712338\n",
      "AUC: 0.9467656565656565 PR_AUC: 0.1599857208278231\n",
      "AUC: 0.9471227272727274 PR_AUC: 0.16360107930645856\n",
      "AUC: 0.9465611111111111 PR_AUC: 0.16601244141719065\n",
      "AUC: 0.9465393939393939 PR_AUC: 0.16703127274846613\n",
      "AUC: 0.9464166666666667 PR_AUC: 0.17026466553502076\n",
      "AUC: 0.946671717171717 PR_AUC: 0.16668583744469112\n",
      "AUC: 0.9474858585858587 PR_AUC: 0.15974815363743677\n",
      "AUC: 0.9472989898989899 PR_AUC: 0.15976577564236358\n",
      "AUC: 0.9474388888888888 PR_AUC: 0.16084494507575542\n",
      "AUC: 0.9474272727272727 PR_AUC: 0.15622140699622783\n",
      "AUC: 0.9472015151515152 PR_AUC: 0.15617338534928102\n",
      "AUC: 0.9472994949494948 PR_AUC: 0.1592946642360823\n",
      "AUC: 0.9469656565656566 PR_AUC: 0.16332509741271653\n",
      "AUC: 0.946679797979798 PR_AUC: 0.15836958134757276\n",
      "AUC: 0.9463338383838383 PR_AUC: 0.15896986156559165\n",
      "AUC: 0.9460843434343434 PR_AUC: 0.16218043099061752\n",
      "AUC: 0.9461070707070709 PR_AUC: 0.16099664231145835\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  10\n",
      "AUC: 0.9474954545454546 PR_AUC: 0.1701417431658785\n",
      "AUC: 0.9480409090909091 PR_AUC: 0.16534750136101492\n",
      "AUC: 0.9468474747474749 PR_AUC: 0.15982490939409064\n",
      "AUC: 0.947010101010101 PR_AUC: 0.1629017268659022\n",
      "AUC: 0.9464954545454545 PR_AUC: 0.16383330731324058\n",
      "AUC: 0.9465818181818182 PR_AUC: 0.16536598442003123\n",
      "AUC: 0.9464792929292929 PR_AUC: 0.1703777547229835\n",
      "AUC: 0.9468666666666665 PR_AUC: 0.16627266468532192\n",
      "AUC: 0.947680303030303 PR_AUC: 0.16658077542538524\n",
      "AUC: 0.9474914141414141 PR_AUC: 0.16672519066261676\n",
      "AUC: 0.947679797979798 PR_AUC: 0.16862666096286352\n",
      "AUC: 0.9475237373737374 PR_AUC: 0.1630493084207213\n",
      "AUC: 0.9467136363636364 PR_AUC: 0.15787574411740757\n",
      "AUC: 0.9464696969696971 PR_AUC: 0.15338692650020616\n",
      "AUC: 0.9460030303030302 PR_AUC: 0.15727004106961032\n",
      "AUC: 0.9466919191919192 PR_AUC: 0.16175342725471203\n",
      "AUC: 0.9464893939393939 PR_AUC: 0.16427069923636953\n",
      "AUC: 0.9464373737373738 PR_AUC: 0.16696489605440232\n",
      "AUC: 0.9463449494949495 PR_AUC: 0.1668991375310371\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  11\n",
      "AUC: 0.9462767676767676 PR_AUC: 0.16135806423132032\n",
      "AUC: 0.9466550505050504 PR_AUC: 0.15894869026448089\n",
      "AUC: 0.9463292929292929 PR_AUC: 0.16064915771850405\n",
      "AUC: 0.9467969696969697 PR_AUC: 0.1630810927150777\n",
      "AUC: 0.9469409090909092 PR_AUC: 0.17162002225349102\n",
      "AUC: 0.9469409090909091 PR_AUC: 0.17253144175805993\n",
      "AUC: 0.9460348484848485 PR_AUC: 0.16579517748648995\n",
      "AUC: 0.9463904040404041 PR_AUC: 0.1624518707309399\n",
      "AUC: 0.9474353535353536 PR_AUC: 0.1595489852446841\n",
      "AUC: 0.9472272727272728 PR_AUC: 0.15869702221218027\n",
      "AUC: 0.9473020202020201 PR_AUC: 0.15895474853216504\n",
      "AUC: 0.9472818181818182 PR_AUC: 0.1556414235551517\n",
      "AUC: 0.9471772727272727 PR_AUC: 0.15808922050678412\n",
      "AUC: 0.9476510101010102 PR_AUC: 0.1628389793689932\n",
      "AUC: 0.9470388888888889 PR_AUC: 0.16216291765147228\n",
      "AUC: 0.9474333333333331 PR_AUC: 0.16456163148203104\n",
      "AUC: 0.9471323232323231 PR_AUC: 0.16590984876762865\n",
      "AUC: 0.9470050505050506 PR_AUC: 0.16762199685678958\n",
      "AUC: 0.94629898989899 PR_AUC: 0.15958677697340445\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  12\n",
      "AUC: 0.9477944444444445 PR_AUC: 0.16901811461402783\n",
      "AUC: 0.9480383838383838 PR_AUC: 0.16667842045845682\n",
      "AUC: 0.9469545454545455 PR_AUC: 0.16062524692517838\n",
      "AUC: 0.9473176767676768 PR_AUC: 0.16249974731178649\n",
      "AUC: 0.9468924242424244 PR_AUC: 0.16346365592409406\n",
      "AUC: 0.9469055555555556 PR_AUC: 0.16492005218220188\n",
      "AUC: 0.9467232323232323 PR_AUC: 0.16825283989978698\n",
      "AUC: 0.9471070707070707 PR_AUC: 0.16553622403985846\n",
      "AUC: 0.9479752525252525 PR_AUC: 0.16716543270081657\n",
      "AUC: 0.9477893939393939 PR_AUC: 0.1659591946652321\n",
      "AUC: 0.9479171717171716 PR_AUC: 0.16756551130330932\n",
      "AUC: 0.9478186868686869 PR_AUC: 0.16271693387811284\n",
      "AUC: 0.9470136363636363 PR_AUC: 0.15617859937794126\n",
      "AUC: 0.946880808080808 PR_AUC: 0.15543135443166706\n",
      "AUC: 0.9464914141414141 PR_AUC: 0.1587954900311828\n",
      "AUC: 0.9470055555555557 PR_AUC: 0.165037724974507\n",
      "AUC: 0.9468398989898991 PR_AUC: 0.16611468315209385\n",
      "AUC: 0.9468621212121212 PR_AUC: 0.16754973354989314\n",
      "AUC: 0.9467772727272727 PR_AUC: 0.16704955297660257\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  13\n",
      "AUC: 0.9473535353535353 PR_AUC: 0.1691275673330538\n",
      "AUC: 0.9476545454545455 PR_AUC: 0.16673539273382426\n",
      "AUC: 0.9466611111111112 PR_AUC: 0.16058023855240663\n",
      "AUC: 0.9470525252525251 PR_AUC: 0.16286310922821381\n",
      "AUC: 0.9465989898989898 PR_AUC: 0.16425242989517047\n",
      "AUC: 0.9466565656565656 PR_AUC: 0.16573029839323797\n",
      "AUC: 0.9463929292929292 PR_AUC: 0.1669096137595495\n",
      "AUC: 0.9466969696969697 PR_AUC: 0.16441825526590106\n",
      "AUC: 0.9476247474747475 PR_AUC: 0.1669397810709152\n",
      "AUC: 0.9477590909090907 PR_AUC: 0.1681906614174138\n",
      "AUC: 0.9478368686868687 PR_AUC: 0.1687757345636863\n",
      "AUC: 0.9477313131313131 PR_AUC: 0.16460318460903098\n",
      "AUC: 0.9468676767676768 PR_AUC: 0.1576398941617435\n",
      "AUC: 0.94675 PR_AUC: 0.15563013335635828\n",
      "AUC: 0.9462196969696971 PR_AUC: 0.15669235332994616\n",
      "AUC: 0.9466025252525252 PR_AUC: 0.16127421256574553\n",
      "AUC: 0.9464722222222222 PR_AUC: 0.16341855890601004\n",
      "AUC: 0.9464646464646465 PR_AUC: 0.166250084783191\n",
      "AUC: 0.946410101010101 PR_AUC: 0.16535410158109456\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  14\n",
      "AUC: 0.9467252525252525 PR_AUC: 0.16265299422865073\n",
      "AUC: 0.9469015151515151 PR_AUC: 0.1607008897154976\n",
      "AUC: 0.9466530303030304 PR_AUC: 0.16166770078299977\n",
      "AUC: 0.9468712121212121 PR_AUC: 0.16382366563411588\n",
      "AUC: 0.9470353535353534 PR_AUC: 0.17248011527768475\n",
      "AUC: 0.9472136363636364 PR_AUC: 0.1744736792129506\n",
      "AUC: 0.9470873737373738 PR_AUC: 0.1764155506093551\n",
      "AUC: 0.9473530303030303 PR_AUC: 0.17351802476045267\n",
      "AUC: 0.9479121212121212 PR_AUC: 0.1692657342939373\n",
      "AUC: 0.9477762626262628 PR_AUC: 0.1685652080553638\n",
      "AUC: 0.947910101010101 PR_AUC: 0.16940658905803135\n",
      "AUC: 0.9478419191919192 PR_AUC: 0.16487022167605891\n",
      "AUC: 0.9469914141414141 PR_AUC: 0.1575322940854165\n",
      "AUC: 0.9469232323232323 PR_AUC: 0.15650776738962563\n",
      "AUC: 0.9466358585858586 PR_AUC: 0.1608031639753824\n",
      "AUC: 0.9472378787878788 PR_AUC: 0.1660783741306822\n",
      "AUC: 0.9471449494949495 PR_AUC: 0.16869531406033464\n",
      "AUC: 0.9470691919191919 PR_AUC: 0.17094651453060153\n",
      "AUC: 0.9469989898989899 PR_AUC: 0.17059637157279198\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  15\n",
      "AUC: 0.9477212121212121 PR_AUC: 0.1710806971022574\n",
      "AUC: 0.9478368686868688 PR_AUC: 0.16998052699022698\n",
      "AUC: 0.9469015151515152 PR_AUC: 0.16223060486191745\n",
      "AUC: 0.9472146464646465 PR_AUC: 0.16455402934905503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9469909090909091 PR_AUC: 0.168396497609875\n",
      "AUC: 0.9471252525252526 PR_AUC: 0.1702400081334907\n",
      "AUC: 0.947169191919192 PR_AUC: 0.17421485621453195\n",
      "AUC: 0.9472787878787878 PR_AUC: 0.17006458761939558\n",
      "AUC: 0.9479621212121211 PR_AUC: 0.17028030014124257\n",
      "AUC: 0.9471737373737374 PR_AUC: 0.16155636389357195\n",
      "AUC: 0.9472560606060606 PR_AUC: 0.1622548893773363\n",
      "AUC: 0.9471813131313132 PR_AUC: 0.1588350852567743\n",
      "AUC: 0.9472272727272727 PR_AUC: 0.16234055980288367\n",
      "AUC: 0.9475929292929293 PR_AUC: 0.16353896449135708\n",
      "AUC: 0.9471313131313132 PR_AUC: 0.16429058474027014\n",
      "AUC: 0.9473247474747474 PR_AUC: 0.1665725120541071\n",
      "AUC: 0.947109090909091 PR_AUC: 0.1687240630145314\n",
      "AUC: 0.9471020202020203 PR_AUC: 0.17008034844722994\n",
      "AUC: 0.9463686868686869 PR_AUC: 0.16201915593285535\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  16\n",
      "AUC: 0.9475323232323232 PR_AUC: 0.17207984749135954\n",
      "AUC: 0.9478232323232324 PR_AUC: 0.16943277338613452\n",
      "AUC: 0.9468550505050505 PR_AUC: 0.16192731653189993\n",
      "AUC: 0.9471020202020202 PR_AUC: 0.16387700149978993\n",
      "AUC: 0.9468045454545454 PR_AUC: 0.16521887395314427\n",
      "AUC: 0.9467949494949496 PR_AUC: 0.16618793292981768\n",
      "AUC: 0.9466898989898991 PR_AUC: 0.1683184548916669\n",
      "AUC: 0.9469262626262626 PR_AUC: 0.16625151731864257\n",
      "AUC: 0.9480530303030302 PR_AUC: 0.1703670410040744\n",
      "AUC: 0.9479267676767678 PR_AUC: 0.16942413622332222\n",
      "AUC: 0.9480055555555555 PR_AUC: 0.16994754276471247\n",
      "AUC: 0.9480035353535353 PR_AUC: 0.16633159300608166\n",
      "AUC: 0.9471616161616162 PR_AUC: 0.15831564852612034\n",
      "AUC: 0.9470772727272727 PR_AUC: 0.15688258577140712\n",
      "AUC: 0.946900505050505 PR_AUC: 0.16256205537524876\n",
      "AUC: 0.9474535353535354 PR_AUC: 0.16816754764046735\n",
      "AUC: 0.9473252525252526 PR_AUC: 0.16945563067649588\n",
      "AUC: 0.9472237373737373 PR_AUC: 0.1710201144570406\n",
      "AUC: 0.9471757575757576 PR_AUC: 0.170482374911377\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  17\n",
      "AUC: 0.9476707070707071 PR_AUC: 0.17156798177942528\n",
      "AUC: 0.9478297979797979 PR_AUC: 0.17035478809217428\n",
      "AUC: 0.9469828282828283 PR_AUC: 0.16266346921834068\n",
      "AUC: 0.9472333333333334 PR_AUC: 0.16456712332982937\n",
      "AUC: 0.9471439393939395 PR_AUC: 0.16940097882238125\n",
      "AUC: 0.9472671717171717 PR_AUC: 0.17137099193910932\n",
      "AUC: 0.9473035353535353 PR_AUC: 0.17546254178725204\n",
      "AUC: 0.9473898989898989 PR_AUC: 0.1713475134932305\n",
      "AUC: 0.9480555555555555 PR_AUC: 0.1715414599156587\n",
      "AUC: 0.94730101010101 PR_AUC: 0.164317013096863\n",
      "AUC: 0.9476530303030302 PR_AUC: 0.16788983070022548\n",
      "AUC: 0.9475742424242424 PR_AUC: 0.1640575341026528\n",
      "AUC: 0.9477363636363635 PR_AUC: 0.16666792118625906\n",
      "AUC: 0.9476474747474748 PR_AUC: 0.16546029256578268\n",
      "AUC: 0.9472343434343434 PR_AUC: 0.16647176090668303\n",
      "AUC: 0.9467929292929291 PR_AUC: 0.16088822064310707\n",
      "AUC: 0.9466181818181818 PR_AUC: 0.16178624839566066\n",
      "AUC: 0.9466525252525253 PR_AUC: 0.16387601599824506\n",
      "AUC: 0.9466005050505052 PR_AUC: 0.1643005556920485\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  18\n",
      "AUC: 0.9477368686868687 PR_AUC: 0.17122251997804439\n",
      "AUC: 0.9478525252525253 PR_AUC: 0.16774900765770254\n",
      "AUC: 0.9469823232323232 PR_AUC: 0.16107134459078276\n",
      "AUC: 0.9472080808080807 PR_AUC: 0.16268315881531875\n",
      "AUC: 0.9469621212121212 PR_AUC: 0.16459283226940763\n",
      "AUC: 0.9470217171717172 PR_AUC: 0.16666529826013843\n",
      "AUC: 0.9470409090909091 PR_AUC: 0.17161676586901708\n",
      "AUC: 0.9471969696969696 PR_AUC: 0.1695443215001047\n",
      "AUC: 0.948030303030303 PR_AUC: 0.17037331846475004\n",
      "AUC: 0.9479131313131314 PR_AUC: 0.16957020785609403\n",
      "AUC: 0.9479792929292928 PR_AUC: 0.17138201785028992\n",
      "AUC: 0.9478712121212122 PR_AUC: 0.1662404244123639\n",
      "AUC: 0.9470308080808081 PR_AUC: 0.1579331952238538\n",
      "AUC: 0.9470050505050505 PR_AUC: 0.15686212994335\n",
      "AUC: 0.9467131313131313 PR_AUC: 0.1597582893794068\n",
      "AUC: 0.9470469696969697 PR_AUC: 0.16572059289642269\n",
      "AUC: 0.9468823232323232 PR_AUC: 0.1647100485696708\n",
      "AUC: 0.9469797979797979 PR_AUC: 0.16720690942860822\n",
      "AUC: 0.9468813131313131 PR_AUC: 0.16846022702227403\n",
      "~~~~~~~~~~~~~~~~~~~~ Epoch:  19\n"
     ]
    }
   ],
   "source": [
    "batch_sz = 10000\n",
    "classifiers = {}\n",
    "weights = [\n",
    "    {0: 0.5, 1:0.5},\n",
    "    {0: 0.9, 1: 0.1},\n",
    "    {0: 0.91, 1: 0.09},\n",
    "    {0 :0.1, 1: 0.9}\n",
    "]\n",
    "curves = {}\n",
    "for w in weights:\n",
    "    print('WEIGHT:', w)\n",
    "    clf_new = SGDClassifier(loss='log', alpha=0.01, class_weight=w)\n",
    "    aucs = []\n",
    "    pr_aucs = []\n",
    "    for i in range(20):\n",
    "        for idxs in chunker(np.arange(len(X_idxs_train)), batch_sz):\n",
    "            x_diff = secondary_scaler_nc.transform(np.abs(XX_train[X_idxs_train[idxs, 0]] - XX_train[X_idxs_train[idxs, 1]]))\n",
    "            x_diff[np.isnan(x_diff)]=0\n",
    "            y = Y_train[idxs]\n",
    "            clf_new.partial_fit(x_diff, y, classes=[0, 1])\n",
    "\n",
    "            probs = clf_new.predict_proba(x_test_diff_sample)[:, 1]\n",
    "\n",
    "            fpr, tpr, thresh = roc_curve(y_test_sample, probs)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            pr_auc = average_precision_score(y_test_sample, probs)\n",
    "\n",
    "            print('AUC:', roc_auc, 'PR_AUC:', pr_auc)\n",
    "        print('~'*20, 'Epoch: ', i)\n",
    "        aucs.append(roc_auc)\n",
    "        pr_aucs.append(pr_auc)\n",
    "    classifiers[str(w)] = clf_new\n",
    "    curves[str(w)] = (aucs, pr_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "total_recs = 75000\n",
    "frac = 0.01\n",
    "X_idxs_neg = np.concatenate([X_idxs_neg_diff_topic, X_idxs_neg_same_topic])\n",
    "p = np.random.choice(range(len(X_idxs_neg)), int(total_recs * (1 - frac)), replace=False)\n",
    "X_idxs_neg_sampled = X_idxs_neg[p]\n",
    "p = np.random.choice(range(len(X_idxs_pos)), int(total_recs * frac), replace=False)\n",
    "X_idxs_pos_sampled = X_idxs_pos[p]\n",
    "\n",
    "X_idxs_test = np.concatenate([X_idxs_pos_sampled, X_idxs_neg_sampled])\n",
    "Y_test = np.array([1] * len(X_idxs_pos_sampled) + [0] * len(X_idxs_neg_sampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: {0: 0.5, 1: 0.5} AUC: 0.981 0.375\n",
      "W: {0: 0.9, 1: 0.1} AUC: 0.961 0.264\n",
      "W: {0: 0.91, 1: 0.09} AUC: 0.957 0.26\n",
      "W: {0: 0.1, 1: 0.9} AUC: 0.95 0.167\n"
     ]
    }
   ],
   "source": [
    "for w, clf in classifiers.items():\n",
    "    probs = []\n",
    "    for idxs in chunker(X_idxs_test, batch_sz):\n",
    "        x_diff = secondary_scaler_nc.transform(np.abs(XX_nc[idxs[:, 0]] - XX_nc[idxs[:, 1]]))\n",
    "        p = clf.predict_proba(x_diff)[:, 1]\n",
    "        probs.extend(p)\n",
    "    fpr, tpr, thresh = roc_curve(Y_test, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    pr_auc = average_precision_score(Y_test, probs)\n",
    "    print('W:', w, 'AUC:', round(roc_auc, 3), round(pr_auc, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
