{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import glob\n",
    "from tqdm.auto import trange, tqdm\n",
    "import openai\n",
    "from features import merge_entries, prepare_entry\n",
    "import nltk\n",
    "from utills import chunker, get_num_chunks\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREPROCESSED_DATA_PATH = '../temp_data/pan/'\n",
    "DATA_DIR = '../data/pan/'\n",
    "GROUND_TRUTH_PATH = DATA_DIR + 'pan20-authorship-verification-training-large-truth.jsonl'\n",
    "TEMP_DATA_PATH = '../temp_data/gpt3_new/'\n",
    "\n",
    "MAX_RECORDS = 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_quotes_and_chunk(doc, sent_size=10):\n",
    "    \"\"\"\n",
    "    Merge all the chunks and split by sentences. Then group again by \n",
    "    `sent_size` chunks. Fix the quotation marks as well\n",
    "    \"\"\"\n",
    "    text =  ' '.join([e['preprocessed'] for e in doc])\n",
    "    text = text.replace('\"', '\\'')\n",
    "    chunks = [' '.join(c) for c in chunker(sent_tokenize(text), sent_size)]\n",
    "    return [prepare_entry(c, mode='accurate', tokenizer='casual') for c in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text, fandom, num_paras):\n",
    "    prompt = (\n",
    "        f\"Complete the next {num_paras} paragraphs from this fanfiction about {fandom}. \" \n",
    "        \"Ensure to use the same writing style as the original fanfiction:\\n\"\n",
    "        f\" {text} \\n\"\n",
    "        \":\"\n",
    "    )\n",
    "#     print(prompt)\n",
    "    response = openai.Completion.create(\n",
    "      model=\"gpt-3.5-turbo-instruct\",\n",
    "      prompt=prompt,\n",
    "      max_tokens=2500,\n",
    "    )\n",
    "\n",
    "    r = response.to_dict()['choices'][0]['text']\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_gpt3_and_human_text_pair(preprocessed_doc, fandom, chunks_per_prompt):\n",
    "    chunks = [merge_entries(c) for c in chunker(preprocessed_doc, chunks_per_prompt)]\n",
    "    human_texts = [c for i, c in enumerate(chunks) if i % 2 == 0]\n",
    "    prompt_texts = [c for i, c in enumerate(chunks) if i % 2 == 1]\n",
    "    num_paras = 100\n",
    "    \n",
    "    generated_texts = [generate(p['preprocessed'], fandom, num_paras) for p in prompt_texts]\n",
    "    generated_texts_preprocessed = [prepare_entry(generated_text, mode='accurate', tokenizer='casual') for generated_text in generated_texts]\n",
    "    return preprocessed_doc, generated_texts_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebea7c40fc254ce0b0194fab79b2ca3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth = {}\n",
    "with open(GROUND_TRUTH_PATH, 'r') as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        ground_truth[d['id']] = d['same']\n",
    "\n",
    "\n",
    "fanfic_recs = []\n",
    "chunk_token_length_total = 0\n",
    "chunk_count = 0\n",
    "with open(PREPROCESSED_DATA_PATH + 'preprocessed_test.jsonl', 'r') as f:\n",
    "    for l in tqdm(f):\n",
    "        d = json.loads(l)\n",
    "        if ground_truth[d['id']] == True:\n",
    "            fixed_d = d.copy()\n",
    "            \n",
    "            \n",
    "            d1 = fix_quotes_and_chunk(d['pair'][0])\n",
    "            d2 = fix_quotes_and_chunk(d['pair'][1])\n",
    "            fixed_d['pair'] = [d1, d2]\n",
    "            \n",
    "            chunk_token_length_total += sum([len(e['tokens']) for e in d1])\n",
    "            chunk_count += len(d1)\n",
    "            chunk_token_length_total += sum([len(e['tokens']) for e in d2])\n",
    "            chunk_count += len(d2)\n",
    "            fanfic_recs.append(fixed_d)\n",
    "        if len(fanfic_recs) > MAX_RECORDS:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average token length of a chunk: 129.95\n"
     ]
    }
   ],
   "source": [
    "avg_chunk_length = chunk_token_length_total/chunk_count\n",
    "print(f\"Average token length of a chunk: {avg_chunk_length:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LLM_token_length = 4096\n",
    "prompt_token_length = int((LLM_token_length / 4) * 0.9) # Slightly lower than 1/4 of LLM token length\n",
    "chunks_per_prompt = int(prompt_token_length/avg_chunk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 921)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_per_prompt, prompt_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_ids = []\n",
    "with open(TEMP_DATA_PATH + 'new_human_gpt3_preprocessed.jsonl', 'r') as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        processed_ids.append(d['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54dbe4443014d4385e8c1ebe878fe28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f8dfc29e-1adb-58f4-888d-a3236124727d True\n",
      "b1a1257b-546b-5363-8d36-82ffa2280eb3 True\n",
      "a71dede2-d06f-5df5-86fa-8784dd22ad5f True\n",
      "ac5ae379-5d9e-5a32-bc66-2078efa70aa1 True\n",
      "a9b8f0d1-aefe-58d8-a210-a276386d8c83 True\n",
      "ef6e8d08-4bc8-581e-b43c-9ec8c10b7be7 True\n",
      "8282b832-e689-581e-8de9-de7961d924fb True\n",
      "dd88b38c-6a4d-5129-a681-b223f4305e5a True\n",
      "86221920-cb49-587a-8236-ae41d3f8aa7c True\n",
      "38cbfaa6-9b98-599a-9bf7-faa43d86f8c7 True\n",
      "5bd631c9-92aa-51f1-b3bd-37a6bdb5eb65 True\n",
      "5ee236b8-4d4b-55e1-93ad-4938d658066d True\n",
      "5df1e0e4-3069-53a9-be3e-9e7f2c0e41f4 True\n",
      "21b74444-5342-5cbf-a92f-cfa0c5066f50 True\n",
      "d5ff3e2b-a4c1-5db0-9a6b-8a660a95125e True\n",
      "d5777bb1-42fa-5c07-b545-2c6e619976f1 True\n",
      "7acb4ce1-02fa-5e88-9e4b-63523ab14153 True\n",
      "b2a5919f-cf65-58d2-9c16-7aa9acf978a4 True\n",
      "0c7ba366-ab87-59d4-b240-4d5cb55aa07c True\n",
      "d5777bb1-42fa-5c07-b545-2c6e619976f1 True\n",
      "7acb4ce1-02fa-5e88-9e4b-63523ab14153 True\n",
      "b2a5919f-cf65-58d2-9c16-7aa9acf978a4 True\n",
      "0c7ba366-ab87-59d4-b240-4d5cb55aa07c True\n",
      "9a5ab6f1-28bd-566c-9125-db4beb8c20b9 True\n",
      "3cfc04b0-eadd-58a9-82f6-237fa88bfae8 True\n",
      "61b9472b-035d-5234-83a9-771eb98a68ae True\n",
      "40318e95-019e-53de-95e6-13419ca3bb60 True\n",
      "30028fb3-7897-57c6-a5ba-21fc5b7009ac True\n",
      "d027b375-5b1a-523e-88e4-6f1b2871e9ed True\n",
      "414e00ec-52cb-50cd-a1f7-9821476e89e1 False\n",
      "53372625-ed59-5f1b-8424-d424bd541497 False\n",
      "1f4ce8af-b8f1-58be-9af4-1c771791daa4 True\n",
      "ba916cba-936e-5ca3-92c6-2a5ea9fdb2bb True\n",
      "cd0fefd9-1629-50c3-a1d4-9565b059ba20 True\n",
      "cf656bd9-d953-52e5-9228-3b7a274a9bc5 True\n",
      "a00d51f0-9434-5bfa-a73b-826d3ae848a5 True\n",
      "b33d4cff-dde8-5543-b80f-e26f8bcbe7a0 True\n",
      "d70f30d0-95df-5cd1-89f8-d8e4293a6e29 True\n",
      "f73036cb-8510-5a72-b1e5-170f5e4ef2cd True\n",
      "d95469f3-04a2-50ef-a691-db6c1b2b4cc0 True\n",
      "eada2009-2f15-5870-9ec1-b4424fced2f7 True\n",
      "c426615a-8d4b-5291-9b98-04af78098e41 True\n",
      "7eec3e06-0886-5134-af91-ac53453e3c1f True\n",
      "3823be11-39fe-5dee-8ef2-e66862f08ce9 True\n",
      "3814a329-ce17-5a92-bdf8-22f8fe31a8db True\n",
      "63372e05-fa3d-5457-908d-5724b58b7b9f True\n",
      "01a0a777-b6be-5a94-a0f0-ccb272ed5bbd True\n",
      "670621e4-f684-5a8e-aeb6-83bea0f841c3 True\n",
      "d6ec2edd-a35a-5b2c-aef8-240ba98df5b9 True\n",
      "25490097-ecdb-5928-baff-d15783e56c2b True\n",
      "4376aa6b-9f6f-55f2-9b1c-9240351fb907 True\n",
      "bae19c08-20a8-5c09-a212-e0135f69d252 True\n",
      "599987f7-40bb-5a6b-9a73-4fd2f4cfa355 True\n",
      "3694d051-91d6-53e1-a13c-4c8506410b3f True\n",
      "59d13041-3257-58af-a42b-16cb7e7ee01b True\n",
      "7ed57a91-8db8-5630-a8ba-6f02d3e3a829 True\n",
      "251ceb22-094b-5c81-9b7a-5d7916cdeea4 True\n",
      "1f405f83-b019-57cb-8591-4c2f7a8377f6 True\n",
      "fc81e4c7-313a-5279-b731-f95984e85b97 True\n",
      "d3afc7dc-2a96-5fb8-a534-5cf85399061f True\n",
      "72e34e60-8107-5535-b60a-7e6efe1be0b9 True\n",
      "e9991562-32df-5421-8e3e-d8fbe65b6079 True\n",
      "8d9e7aee-a273-5822-84dc-ffc5844c9809 True\n",
      "4f3630ba-ab2d-5b5a-8492-c602db678a77 True\n",
      "0ec052c4-a55b-52f6-989a-5e9f3c6291dc True\n",
      "830b3426-8056-56d4-864e-c9e70781230c True\n",
      "aec9151c-d02c-5576-aff6-175fe0980a87 True\n",
      "21f4f73f-f442-560c-a9d0-b9e0fc27ea0c True\n",
      "11334f3c-fd4e-549a-9a57-62d85f7ccd9e True\n",
      "eb48d88e-d135-551d-8a97-8485be13fe63 True\n",
      "a3e650ab-d952-5e26-8c9d-e206267cc420 True\n",
      "75a6bc91-45fa-5648-9acc-70bb0922dbe1 True\n",
      "6d79027d-123d-5179-967e-f317dc4ee838 True\n",
      "030093fa-e997-5888-8f20-765085411431 True\n",
      "f0ecb4d4-c16d-5fad-9160-018952e2dbb6 True\n",
      "3d8480f9-b309-5a63-9cb7-3200129e7d65 True\n",
      "3b22f598-cd00-52e6-ab74-4dec056b6d5d True\n",
      "b73ad7be-f7b5-533d-81b0-43e0b6d7cc58 True\n",
      "090c5654-67d1-5f00-9933-d5d1b32fb658 True\n",
      "138b4e60-8613-504d-951e-acafc2821edc True\n",
      "08633496-d905-5759-a55e-75fc08a5f64b True\n",
      "e2b17624-ba31-5611-bf68-60b76d83982c True\n",
      "117e2152-87a1-58de-b512-980984558c51 True\n",
      "bcc9e7e5-2692-5b7a-92fd-c04d0e3c797d True\n",
      "0de07c6c-dd35-56b6-a8fa-ba2de7411675 True\n",
      "40b72375-f45a-57dd-888d-0dbeb1c3f874 True\n",
      "3ab456ae-5bf9-52d4-82d8-7af933304cb2 True\n",
      "1ce3749a-bc41-57f5-a12a-e8331dc37978 True\n",
      "edd3ca9d-24eb-53c3-894f-cfdd816ba7d0 True\n",
      "74586320-af5c-5cae-a410-cada791357df True\n",
      "9516e7f7-9bca-529f-a8a4-0fced689e2ae True\n",
      "452a820d-0f32-517a-bb22-1c1f754d8ccc True\n",
      "54b62ab4-b0aa-5e8d-8843-4805fb4fe455 True\n",
      "bd94c501-dfbb-550d-b6e1-c800011d8c7e True\n",
      "9ba0c1b7-dfa0-54ac-9748-715b18b1cd29 True\n",
      "7befbe15-7382-533d-bb3c-c5d274f8f2a5 True\n",
      "0092fece-8942-51bb-bba6-c55851c1d6ba True\n",
      "84b3f885-d974-5ec1-9d94-363e9212e2ed True\n",
      "6f1c38e0-fb3e-5b41-9fed-84b4913d5459 True\n",
      "8b6bbe3a-062f-5272-98e7-796def89c255 True\n",
      "04f70001-26dd-56b7-82e8-f3a45ca460b3 True\n",
      "6bbb5125-6e7c-58e8-a195-b735cf315099 False\n",
      "Human Doc 1:  4728\n",
      "AI Doc 1:  3571\n",
      "Human Doc 2:  4534\n",
      "AI Doc 2:  3527\n",
      "fd5890a8-df8b-5173-b74b-62a0f28ecff8 False\n",
      "Human Doc 1:  4795\n",
      "AI Doc 1:  3482\n",
      "Human Doc 2:  4682\n",
      "AI Doc 2:  4710\n",
      "ad4a2215-ec39-58cf-8e9f-d1588bcacb7b False\n",
      "Human Doc 1:  4474\n",
      "AI Doc 1:  1742\n",
      "Human Doc 2:  4364\n",
      "AI Doc 2:  2676\n",
      "cbc5925b-10bd-5db5-af9a-207cf997d8cb False\n",
      "Human Doc 1:  4335\n",
      "AI Doc 1:  2248\n",
      "Human Doc 2:  4684\n",
      "AI Doc 2:  3796\n",
      "fcb920b6-3d18-5c8f-a85c-9cd580e28dca False\n",
      "Human Doc 1:  4511\n",
      "AI Doc 1:  2993\n",
      "Human Doc 2:  4682\n",
      "AI Doc 2:  4891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# processed_ids = []\n",
    "with open(TEMP_DATA_PATH + 'new_human_gpt3_preprocessed.jsonl', 'a') as f_out:\n",
    "    for d in tqdm(fanfic_recs):\n",
    "        print(d['id'], d['id'] in processed_ids, flush=True)\n",
    "        if d['id'] in processed_ids:\n",
    "            continue\n",
    "        try:\n",
    "            d1_human, d1_ai = generate_gpt3_and_human_text_pair(d['pair'][0], d['fandoms'][0], chunks_per_prompt)\n",
    "            print(\"Human Doc 1: \", len(merge_entries(d1_human)['tokens']))\n",
    "            print(\"AI Doc 1: \", len(merge_entries(d1_ai)['tokens']))\n",
    "\n",
    "            d2_human, d2_ai = generate_gpt3_and_human_text_pair(d['pair'][1], d['fandoms'][1], chunks_per_prompt)\n",
    "            print(\"Human Doc 2: \", len(merge_entries(d2_human)['tokens']))\n",
    "            print(\"AI Doc 2: \", len(merge_entries(d2_ai)['tokens']))\n",
    "\n",
    "            preprocessed = {\n",
    "                'id': d['id'],\n",
    "                'fandoms': d['fandoms'],\n",
    "                'pair': [\n",
    "                    {'human': d1_human, 'ai': d1_ai},\n",
    "                    {'human': d2_human, 'ai': d2_ai}\n",
    "                ]\n",
    "            }\n",
    "            json.dump(preprocessed, f_out)\n",
    "            f_out.write('\\n')\n",
    "            f_out.flush()\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'openai' from '/media/disk1/social/.local/lib/python3.6/site-packages/openai/__init__.py'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
